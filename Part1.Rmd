---
title: "SC_Tutorial_part1"
date: "`r BiocStyle::doc_date()`"
output: 
    BiocStyle::html_document2:
        keep_md: yes
        toc_float: true
author:
- name: Atul Sethi
  email: atul.sethi@fmi.ch
- name: Michael Stadler
  email: michael.stadler@fmi.ch
- name: Panagiotis Papasaikas
  email: panagiotis.papasaikas@fmi.ch  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Single Cell Analysis Tutorial Part 1

## Example Dataset 

To illustrate the various aspects of SC analysis, we will use a 
[dataset](http://www.biorxiv.org/content/early/2016/07/08/062919) of
 induced pluripotent stem cells generated from three different individuals generated in [Yoav Gilad](http://giladlab.uchicago.edu/)'s lab at the
University of Chicago. The experiments were carried out on the
Fluidigm C1 platform and to facilitate the quantification both unique
molecular identifiers (UMIs) and ERCC _spike-ins_ were used. The data files are located in the `data\tung` folder in your working directory.

Load the data and annotations:

```{r load_data}
umi_counts <- read.table("data/tung/molecules.txt", sep = "\t")
read_counts <- read.table("data/tung/reads.txt", sep = "\t")
anno <- read.table("data/tung/annotation.txt", sep = "\t", header = TRUE)
```

Inspect a small portion of the expression matrix:

```{r small_output}
head(umi_counts[ , 1:3])
```

We will also load a few functions that will be used during the training:
```{r source_helper_functions, message=FALSE}
source("helper_functions.R")
```

The most important characteristic of all SC RNAseq assays that sets them apart from bulk RNAseq is the small starting RNA amounts per cell
that results in high sampling noise. This can be evidenced in the correlation of gene counts between pairs of cells:


```{r cell2cell}
plot(log2(umi_counts[ , 1]+1), log2(umi_counts[ , 2]+1), pch=19, xlab="Cell1", ylab="Cell2")
```

## Quality control (QC) and important quantitative traits of the dataset

We will now look into some of the most important general quantitative traits of the dataset.
These traits provide a first line of quality assessment of the experiment and the individual cells. As such, they can be used
during data pre-processing as quality filters (see next section).
These traits inlude:

* Transcript Capture efficiency
* Library size and Number of detected genes
* Sensitivity and accuracy 
* Ratio between ERCC spike-ins RNAs and endogenous RNAs 
* Amplification rate (per gene / per cell)  
* Proportion of reads in mitchondrial (MT) genes.
* Gene dispersion as a function of their mean expression (Mean-variance trend)

### Transcript Capture efficiency
Capture efficiency is the proportion of transcript molecules present in a cell that are detected in the final cell library.
Capture efficiency varies widely among different SC RNA seq platforms and can be anywhere between x and y %.
Capture efficiency can also vary among different cells within a single experiment (e.g because of RNA degradation, incomplete cell lysis...)
For a given gene the probability of detection is (obviously) a function of its level of expression:

```{r detection_probability}
smoothScatter(log2(rowSums(umi_counts)+1),rowSums(umi_counts>0)/ncol(umi_counts) ,xlab=expression(Log[2]~"Total gene count"),ylab="Detection probability"    )
```

### Library size and number of detected genes.
Library size is the number of unique transcript molecules that are detected in a cell:

```{r library_size}
hist(colSums(umi_counts)/1e6, xlab="Library size (millions)", main="", breaks=20, col="grey80", ylab="Number of cells")
```

Two indices related to library size are the number of detected genes and its converse, the number of dropout values (undetected genes):
```{r ndet_genes}
par(mfrow=c(1,2))
hist(colSums(umi_counts>0),  xlab="Library sizes", main="", breaks=20, col="grey80", ylab="Number of cells")
hist(colSums(umi_counts==0), xlab="Number of dropout values", main="", breaks=20, col="grey80", ylab="Number of cells")
```

Library size and number of detected genes depend on overall transcript capture efficiency but also on the identity and state of the individual cells.

It is often convenient/useful to normalize the count table to the cells' library sizes:
```{r library_normalization}
norm_umi_counts=sweep(umi_counts,2,colSums(umi_counts),FUN="/")*1000000 #Normalize for library size and convert to CPMs
```


### Sensitivity and accuracy
When ERCC spike-ins are available we can estimate the sensitivity of the experiment, that is, the minimum number of molecules required for detection (an indicator of capture efficiency) as well as its accuracy (relationship estimated abundance to ground truth).
First we need a list of the features that correspond to ERCCs and their loading concentrations:
```{r get_ERCC_info}
ERCC <- rownames(umi_counts)[(grepl("ERCC-", rownames(umi_counts)))]
#### The following chunk of code could be moved to the helper functions and be transparent
ERCCdata <- read.table("data/ERCC_conc.txt", sep = "\t",header=TRUE)
ERCCconc <- as.matrix(ERCCdata[,4])
dimnames(ERCCconc)=list(ERCCdata[,2],colnames(ERCCdata)[4])
```
Now we can plot the ERCC counts in every cell as a function of the ERCCs' loading concentation:
```{r plot_ERCC_conc}
smoothScatter( rep(log2(ERCCconc[ERCC,1]),ncol(umi_counts) ) ,log2(as.vector(as.matrix(norm_umi_counts[ERCC,]+1))),  xlab="Log2 ERCC concentration (attomoles/ul)",ylab="Log2 UMI counts")
```

Note that the sensitivity and accuracy values based on the ERCCs are only rough estimates since ERCCs have different capture efficiency and amplification biases from endgenous RNA molecules. 

### Amplification rate
The amplification rate is the number of times a single originating molecule is amplified during library preparation.
Increased amplification rates in a cell can be indicators  of low starting RNA amounts and thus could pinpoint low quality/spurious cells.
On the other hand the per gene amplification rates can be useful in determing the level of saturation of the sequenced libraries.
The great advantage of sequencing platforms with UMIs is that amplification rates can be estimated and corrected for:

```{r amplif_rate}
hist( colMeans(read_counts/(umi_counts+1) ),  xlab="Mean per gene amplification rate", main="", breaks=20, col="grey80", ylab="Number of cells")
```


### Ratio between ERCC spike-ins and endogenous RNAs
ERCC spike-ins can also be used for identifying cells of low quality. This can be done by determing the proportion of reads originating from the spike-ins.
```{r pct_ERCC}
#### Plot the fraction of ERCC-originating reads as a function of number of detected genes and colout by batch:
plot (colSums(umi_counts>0),colSums(umi_counts[ERCC,])/colSums(umi_counts) ,pch=19,col= as.numeric(anno[,4]),xlab="Number of detected genes",ylab="Fraction of ERCC originating reads")
legend ("topleft",legend=unique(anno[,4]),  col= as.numeric(unique(anno[,4])),pch=19, title="Batch" )
```
High fraction of ERCC originating molecules point to low starting cell RNA amounts.
Here we can observe the number of detected genes is a decreasing fraction of the fraction of ERCC originating reads. In addition there is one batch that appears problematic in that its cells have consistently a higher fraction of ERCC-originating reads.


### Proportion of mitochondrial (MT) reads
The proportion of MT reads is another useful indicator of cell quality. High numbers of MT reads can be associated to cell damage.
First we construct a list of the gene features of MT origin:
```{r get_MT_genes}
mt <- c("ENSG00000198899", "ENSG00000198727", "ENSG00000198888",
        "ENSG00000198886", "ENSG00000212907", "ENSG00000198786",
        "ENSG00000198695", "ENSG00000198712", "ENSG00000198804",
        "ENSG00000198763", "ENSG00000228253", "ENSG00000198938",
        "ENSG00000198840")
```

Next we will plot the fraction of MT UMIs as a proportion of the total and color by batch:
```{r pct_MT}
#### Plot the fraction of MT reads as a function of number of detected genes and colout by batch:
plot (colSums(umi_counts>0),colSums(umi_counts[mt,])/colSums(umi_counts) ,pch=19,col= as.numeric(anno[,4]),xlab="Number of detected genes",ylab="Fraction of MT reads")
```

### Gene dispersion as a function of their mean expression (Mean-variance trend)
Variation in gene abundance estimates between different cells can be thought of as the convolution of the technical (mainly sampling) and the biological (e.g cell type) sources of variance. Typically one wants to isolate and focus on the biological variance so that differences due to experimental noise have as small an impact as possible on subsequent analyses.  
As might be intuitevely obvious the effects of sampling noise on our estimates of relative gene abundance decrease with higher levels of gene expression. For example we expect two measurements of a highly expressed gene in two cells of the same type to be more consistent than two measurements of a rare gene (where big fold change differences can be expected just because of chance). This simple intuition is nicely captured in a plot of the gene's dispersion as a function of the mean gene expression also known as the *mean variance trend*. Here as a measure of dispersion we will use the coefficient of variation (cv=variance/mean):

```{r mean_cv_plot}
mean_GE=rowMeans(norm_umi_counts+1/ncol(norm_umi_counts))
gene_cv=apply(norm_umi_counts,1, function(x) sd(x)/mean(x+1/length(x)) )
X1=log2(mean_GE[which(rowSums(norm_umi_counts)>0)])
Y1=log2(gene_cv[which(rowSums(norm_umi_counts)>0)]+1/ncol(norm_umi_counts)  )
m=lm(Y1 ~ X1)
plot(X1,Y1,xlab="log2(mean gene expression)",ylab="log2(coefficent of variation)" ,main="mean-variance trend" )
abline(coef(m)[1],coef(m)[2],col="red",lwd=2,lty=2) # Linear regression on the data
abline(coef(m)[1],-0.5,col="grey",lwd=2,lty=2) # Slope in m-v trend according to poisson distribution
```
Our fit (red line) represents, for this dataset, the expected variance of a gene when the only source of variance is technical (because of sampling).
Genes that fall far above this line are  *overdispersed* and should be enriched for genes the fluctuation of which is of biological origin. 



## Cell and Gene Filtering
The goal of this section is to perform a clean-up of the dataset in two dimensions:
First to remove low quality cells that might otherwise be mistaken for distinct meaningful groupings.
Second to remove uninformative genes so as to bring out the true biological differences and remove as much as possible of the technical variation.
To this end we shall use several of the indices introduced in the previous section. 

Although the exact parameters of filtering largely depend on the specific platform used and the specifics of the experiment the criteria used below can be applied with small modifications to any SC experiment. As a general guideline we should make an effort to remove  clear outlier cells/noisy genes but still be conservative enough so as to avoid throwing out cells/genes with differences of truly biological origin.

### Cell filtering
We will remove cells according to three criteria introduced above:

* Number of detected genes: In a plot of the number of the detected genes of the cells vs the corresponding rank we often observe a point of sudden drop (a shoulder). Numbers below that point might indicate damaged cells:
```{r filter_low_NODG}
NODG=colSums(umi_counts>0)
plot (  rank(-NODG)  , NODG ,col=as.numeric(anno[,4]),pch=19 )
abline(5500,0,col="red")
low_NODG=which(NODG<5500)
```

* Fraction of ERCC-originating reads: As mentioned above high fractions of ERCC-originating reads are also indicative of low cell quality. We already saw that 
one batch  (NA19098.r2) appeared particurarly problematic in this respect and we shall therefore remove it.
```{r filter_high_ERCC}
high_ERCC=which(anno[,4]=="NA19098.r2")
```

* Fraction of MT reads: As noted previously high fractions of MT reads might indicate damaged cells. We will look, as in the case of number of detected genes, for a point in the plot where the fraction of MT reads of the cells when sorted by their rank appear to rise sharply:
```{r filter_high_MT}
fractionMTreads=colSums(umi_counts[mt,])/colSums(umi_counts)
plot (  rank(fractionMTreads)  , fractionMTreads,col=as.numeric(anno[,4]),pch=19 )
abline(0.11,0,col="red")
high_MT=which(fractionMTreads>0.11)
```

We will now combine the three applied filters to obtain a list of all cells that will be removed and obtain filtered versions of our data:
```{r filter_cells}
filtered_cells=unique(c(low_NODG,high_ERCC,high_MT))
clean_umi_counts=umi_counts[,-filtered_cells]
clean_norm_umi_counts=norm_umi_counts[,-filtered_cells] 
clean_anno=anno[,-filtered_cells]
```


### Gene filtering
The goal here is to throw out genes that offer no information as to the biological variance of the cells. We will now work on the cell-filtered version of our data.
A first simple gene filter is to remove all genes that are not detected in ANY of the remaining cells:
```{r absent_genes}
absent_genes=which(rowSums(clean_umi_counts)==0)
clean_umi_counts=clean_umi_counts[-absent_genes,]
clean_norm_umi_counts=clean_norm_umi_counts[-absent_genes,] 
```

A second more elaborate filter will aim to remove genes that do not present cell-to-cell fluctuations above what is expected due to technical variation. 
One possible approach would be to use the mean-variance trend fit constructed above and keep only genes falling above the fitted line:
```{r mean_cv_plot2}
mean_GE=rowMeans(clean_norm_umi_counts+1/ncol(clean_norm_umi_counts))
gene_cv=apply(clean_norm_umi_counts,1, function(x) sd(x)/mean(x+1/length(x)) )
X1=log2(mean_GE)
Y1=log2(gene_cv+1/ncol(clean_norm_umi_counts)  )
m=lm(Y1 ~ X1)
Yhat=predict(m)
col=rep("black",length(Y1))
col[which(Yhat>Y1)]="grey"
plot(X1,Y1,xlab="log2(mean gene expression)",ylab="log2(coefficent of variation)" ,main="mean-variance trend",pch=19 ,col=col)
abline(coef(m)[1],coef(m)[2],col="red",lwd=2,lty=2) # Linear regression on the data
```

A somewhat better approach that relies on fewer assumptions about the mean-variance relationship is to split the genes in bins according to their gene expression and then select the top x% overdispersed genes from every bin. This is achieved using the select_variable_genes function which can be found in the helper functions.R script:
```{r select_overdispersed}
##Specify the normalized count matrix and fraction of overdispersed genes to retain:
genes_keep <- select_variable_genes(clean_norm_umi_counts,0.5)
```


Let's look where our selected genes fall on our mean-variance trend plot:
```{r mean_cv_plot3}
col=rep("grey",length(Y1))
col[genes_keep]="black"
plot(X1,Y1,xlab="log2(mean gene expression)",ylab="log2(coefficent of variation)" ,main="mean-variance trend" ,pch=19,col=col)
abline(coef(m)[1],coef(m)[2],col="red",lwd=2,lty=2) # Linear regression on the data
```
As you can see the effect on this particular dataset is very subtle compared to the previous approach but in different datasets the effect can be more pronounced.



# Single Cell Analysis Tutorial Part 2


## Data Visualization (PCA and tSNE)
In this section we will illustrate different ways to visualize our data using two commonly used approaches, namely Principal Component Analysis (PCA) and t-Distributed Stochastic Neighbor Embedding (tSNE). We will also use these techniques to illustrate what is the effect of selecting only a top fraction of overdispersed genes for data visualization (and consequently cell clustering). 

### PCA
Principal Component Analysis is a linear transformation procedure that identifies the directions of maximum variance in high-dimensional data and projects it in a lower dimension subspace. Every direction is orthogonal to the previously identified ones and therefore the final result is a projection on a new coordinate system that still retains the maximum possible variance. 
A perhaps more intuitive explanation is that PCA seeks summary features (i.e components), that are originally not explicitly there, that capture well the overall dispersion (variance) of our data. Each subsequent summary feature (component) captures the maximum possible dispersion left behind from the previous components. The only condition is that every new summary feature must be uncorrelated (i.e orthogonal) to all the previous ones. Therefore each added summary feature will account for progressively lower fractions of the overall dataset dispersion. A dataset where only a handful of such summary features capture a large part of its overall dispersion can thus be nicely summarized with a number of new features that is only a small fraction of the original ones.


## Identification of confounding factors and correction for unwanted sources of variance

## Identification of meaningful biological cell groupings (clustering) 

## Differential gene expression 

```{r setup_documentation, echo=FALSE, message=FALSE, results='hide'}
#### Copy the created html to master root as index.html
#### and the md as README.md
  file.copy("Part1.html","index.html",overwrite=TRUE)
```

