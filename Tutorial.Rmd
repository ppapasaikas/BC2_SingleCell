---
title: "SC_Tutorial_part1"
date: "`r BiocStyle::doc_date()`"
output: 
    BiocStyle::html_document2:
        keep_md: yes
        toc_float: true
        md_document:
        variant: markdown_github
author:
- name: Atul Sethi
  email: atul.sethi@fmi.ch
- name: Michael Stadler
  email: michael.stadler@fmi.ch
- name: Panagiotis Papasaikas
  email: panagiotis.papasaikas@fmi.ch  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Single Cell Analysis Tutorial Part 1

## Example Dataset 

To illustrate the various aspects of SC analysis, we will use a 
[dataset](http://www.biorxiv.org/content/early/2016/07/08/062919) of
 induced pluripotent stem cells generated from three different individuals generated in [Yoav Gilad](http://giladlab.uchicago.edu/)'s lab at the
University of Chicago. The experiments were carried out on the
Fluidigm C1 platform and to facilitate the quantification both unique
molecular identifiers (UMIs) and ERCC _spike-ins_ were used. The data files are located in the `data\tung` folder in the [/home/radmin/BC2_SingleCell] directory .

Load the data and annotations:

```{r load_data}
PATH="/home/radmin/BC2_SingleCell/" #Abs Path to BC2 repo in the the ext-fmi machine
PATH=""
umi_counts=readRDS(file=paste(PATH, "data/tung/umi_counts.rds",sep=""))
read_counts=readRDS(file=paste(PATH, "data/tung/read_counts.rds",sep=""))
anno <- read.table(paste(PATH, "data/tung/annotation.txt",sep="") , sep = "\t", header = TRUE) #This is cell annotation (originating individual, chip...)
```

Inspect a small portion of the (umi-collapsed) expression matrix:

```{r small_output}
head(umi_counts[ , 1:3])
```

We also load some information on the ERCC loading concentration as well as gene symbol annotation for the endogenous genes (non-ERCC features) of our expression matrix:
```{r get_gene_annot, include=FALSE}
#library(biomaRt)
#ENS=getBM(attributes=c('ensembl_gene_id', 'hgnc_symbol'),filters='ensembl_gene_id',values=endog,mart=useEnsembl(biomart="ensembl", dataset="hsapiens_gene_ensembl") )
#rownames(ENS)=ENS[,1]
#ENS2HGNC=data.frame(ensembl_gene_id=endog, hgnc_symbol=ENS[endog,2],row.names=endog)
#ERCCdata <- read.table(paste(PATH, "data/ERCC_conc.txt",sep="") , sep = "\t",header=TRUE)
#ERCCconc <- as.matrix(ERCCdata[,4])
#dimnames(ERCCconc)=list(ERCCdata[,2],colnames(ERCCdata)[4])
```

```{r get_ERCC_and_gene_annot_info}
ERCC <- rownames(umi_counts)[(grepl("ERCC-", rownames(umi_counts)))]
endog <- setdiff (rownames(umi_counts),ERCC) #Endogenous genes are the set difference between all genes and ERCCs
ERCCconc=readRDS( file=paste(PATH, "data/tung/ERCCconc.rds",sep="")   ) #Loading concentrations of ERCCs
ENS2HGNC=readRDS( file=paste(PATH, "data/tung/ENS2HGNC.rds",sep="")   ) #Gene symbol annotation for the endogenous gene features
```



Finally we will also load a few packages and functions that will be used during the training:
```{r source_helper_functions, message=FALSE}
source(paste(PATH, "helper_functions.R",sep=""))
```

The most important characteristic of any SC RNAseq assay that sets them apart from bulk RNAseq is the small starting RNA amounts per cell
that results in high sampling noise. This can be evidenced in the correlation of gene counts between pairs of cells:


```{r cell2cell}
plot(log2(umi_counts[endog , 1]+1), log2(umi_counts[endog , 2]+1), pch=19, xlab="Cell1", ylab="Cell2")
```

## Quality control (QC) and important quantitative traits of the dataset

We will now look into some of the most important general quantitative traits of the dataset.
These traits provide a first line of quality assessment of the experiment and the individual cells. As such, they can be used
during data pre-processing as quality filters (see next section).
These traits inlude:

* Transcript Capture efficiency
* Library size and Number of detected genes
* Sensitivity and accuracy 
* Ratio between ERCC spike-ins RNAs and endogenous RNAs 
* Amplification rate (per gene / per cell)  
* Proportion of reads in mitchondrial (MT) genes.
* Gene dispersion as a function of their mean expression (Mean-variance trend)

### Transcript Capture efficiency
Capture efficiency is the proportion of transcript molecules present in a cell that are detected in the final cell library.
Capture efficiency varies widely among different SC RNA seq platforms and can be anywhere between x and y %.
Capture efficiency can also vary among different cells within a single experiment (e.g because of RNA degradation, incomplete cell lysis...)
For a given gene the probability of detection is (obviously) a function of its level of expression:

```{r detection_probability}
smoothScatter(log2(rowSums(umi_counts[endog,])+1),rowSums(umi_counts[endog,]>0)/ncol(umi_counts) ,xlab=expression(Log[2]~"Total gene count"),ylab="Detection probability"    )
points(log2(rowSums(umi_counts[ERCC,])+1),rowSums(umi_counts[ERCC,]>0)/ncol(umi_counts) ,pch=19,col="red"   )
```

### Library size and number of detected genes.
Library size is the number of unique transcript molecules that are detected in a cell:

```{r library_size}
hist(colSums(umi_counts[endog,])/1e6, xlab="Library size (millions)", main="", breaks=20, col="grey80", ylab="Number of cells")
```

Two indices related to library size are the number of detected genes and its converse, the number of dropout values (undetected genes):
```{r ndet_genes}
par(mfrow=c(1,2))
hist(colSums(umi_counts>0),  xlab="Number of detected genes", main="", breaks=20, col="grey80", ylab="Number of cells")
hist(colSums(umi_counts==0), xlab="Number of dropout values", main="", breaks=20, col="grey80", ylab="Number of cells")
```

Library size and number of detected genes depend on overall transcript capture efficiency but also on the identity and state of the individual cells.

It is often convenient/useful to normalize the count table to the cells' library sizes:
```{r library_normalization}
norm_umi_counts=sweep(umi_counts,2,colSums(umi_counts),FUN="/")*1000000 #Normalize for library size and convert to CPMs
```



### Genes accounting for the majority of reads
Typically in any particular cell (and by extension in the whole dataset) the majority of reads originate from a very small fraction of genes. 
For example let's look at the fraction of reads coming from just the top 25 genes in this experiment:

```{r reads_per_gene}
ReadsPerGene=sort(rowSums(umi_counts[endog,]),decreasing=TRUE) #Sort genes in decreasing order in terms of their expression
CumulFraction=cumsum(ReadsPerGene)/sum(ReadsPerGene) #Cumulative fraction of reads
ReadFraction=apply(umi_counts[endog,], 2, function(x) x[names(ReadsPerGene)]/sum(x)  ) #Fraction of reads coming from the genes calculated for each cell 

n=25
f=signif(CumulFraction[n]*100,digits=3)
title=paste("Top ", n,  " genes acccount for ", f, "% of the reads",sep="")
boxplot(ReadFraction[n:1,],use.cols=FALSE,horizontal=TRUE,outline=FALSE,boxwex=0.5,
        names=ENS2HGNC[rownames(ReadFraction)[n:1],2],col="orange",
        main=paste("Top ", n,  " genes acccount for ", f, "% of the reads",sep=""),
        las=2,par(cex.axis=0.6,cex.main=0.9),xlab="Fraction of Reads in Cell" )

```
Notice that the list of top genes is dominated by Mitochondrial (MT...) and robosomal-protein coding (RP...) genes. 
Should these genes be retained in subsequent analysis steps?



### Sensitivity and accuracy
When ERCC spike-ins are available we can estimate the sensitivity of the experiment, that is, the minimum number of molecules required for detection (an indicator of capture efficiency) as well as its accuracy (relationship estimated abundance to ground truth).

Now we can plot the ERCC counts in every cell as a function of the ERCCs' loading concentation:
```{r plot_ERCC_conc}
smoothScatter( rep(log2(ERCCconc[ERCC,1]),ncol(umi_counts) ) ,log2(as.vector(norm_umi_counts[ERCC,]+1)),  xlab="Log2 ERCC concentration (attomoles/ul)",ylab="Log2 norm. UMI counts")
```

Note that the sensitivity and accuracy values based on the ERCCs are only rough estimates since ERCCs have different capture efficiency and amplification biases from endgenous RNA molecules. 

### Amplification rate
The amplification rate is the number of times a single originating molecule is amplified during library preparation.
Increased amplification rates in a cell can be indicators  of low starting RNA amounts and thus could pinpoint low quality/spurious cells.
On the other hand the per gene amplification rates can be useful in determing the level of saturation of the sequenced libraries.
The great advantage of sequencing platforms with UMIs is that amplification rates can be estimated and corrected for:

```{r amplif_rate}
##hist( colMeans(read_counts/(umi_counts+1) ),  xlab="Mean per gene amplification rate", main="", breaks=20, col="grey80", ylab="Number of cells")
NZ_endog=endog[ which(umi_counts[endog,1]>0) ] #Endogenous genes detected in the first cell
smoothScatter( log2(read_counts[NZ_endog,1]+1), log2(umi_counts[NZ_endog,1]+1) ,xlab="Log2(read counts)", ylab="Log2(umi counts)"   )
points( log2(read_counts[ERCC,1]+1), log2(umi_counts[ERCC,1]+1) ,pch=".",col="red",cex=5   )
```


### Ratio between ERCC spike-ins and endogenous RNAs
ERCC spike-ins can also be used for identifying cells of low quality. This can be done by determing the proportion of reads originating from the spike-ins.
```{r pct_ERCC}
#### Plot the fraction of ERCC-originating reads as a function of number of detected genes and colout by batch:
plot (colSums(umi_counts>0),colSums(umi_counts[ERCC,])/colSums(umi_counts) ,pch=19,col= as.numeric(anno[,4]),xlab="Number of detected genes",ylab="Fraction of ERCC originating reads")
legend ("topleft",legend=unique(anno[,4]),  col= as.numeric(unique(anno[,4])),pch=19, title="Batch" )
```
High fraction of ERCC originating molecules point to low starting cell RNA amounts.
Here we can observe the number of detected genes is a decreasing fraction of the fraction of ERCC originating reads. In addition there is one batch that appears problematic in that its cells have consistently a higher fraction of ERCC-originating reads.


### Proportion of mitochondrial (MT) reads
The proportion of MT reads is another useful indicator of cell quality. High numbers of MT reads can be associated to cell damage.
First we construct a list of the gene features of MT origin:
```{r get_MT_genes}
mt <- as.vector(ENS2HGNC[endog,1][grep("^MT-", ENS2HGNC[endog,2])])
#rib.prot <- as.vector(ENS2HGNC[endog,1][grep("^RP", ENS2HGNC[endog,2])])

```

Next we will plot the fraction of MT UMIs as a proportion of the total and color by batch:
```{r pct_MT}
#### Plot the fraction of MT reads as a function of number of detected genes and colout by batch:
plot (colSums(umi_counts>0),colSums(umi_counts[mt,])/colSums(umi_counts) ,pch=19,col= as.numeric(anno[,4]),xlab="Number of detected genes",ylab="Fraction of MT reads")
```

### Gene dispersion as a function of their mean expression (Mean-variance trend)
Variation in gene abundance estimates between different cells can be thought of as the convolution of the technical (mainly sampling) and the biological (e.g cell type) sources of variance. Typically one wants to isolate and focus on the biological variance so that differences due to experimental noise have as small an impact as possible on subsequent analyses.  
As might be intuitevely obvious the effects of sampling noise on our estimates of relative gene abundance decrease with higher levels of gene expression. For example we expect two measurements of a highly expressed gene in two cells of the same type to be more consistent than two measurements of a rare gene (where big fold change differences can be expected just because of chance). This simple intuition is nicely captured in a plot of the gene's dispersion as a function of the mean gene expression also known as the *mean variance trend*. Here as a measure of dispersion we will use the coefficient of variation (cv=variance/mean):

```{r mean_cv_plot}
mean_GE=rowMeans(norm_umi_counts+1/ncol(norm_umi_counts))
gene_cv=apply(norm_umi_counts,1, function(x) sd(x)/mean(x+1/length(x)) )
X1=log2(mean_GE[which(rowSums(norm_umi_counts)>0)])
Y1=log2(gene_cv[which(rowSums(norm_umi_counts)>0)]+1/ncol(norm_umi_counts)  )
m=lm(Y1[endog] ~ X1[endog])
plot(X1[endog],Y1[endog],xlab="log2(mean gene expression)",ylab="log2(coefficent of variation)" ,main="mean-variance trend",pch='.',cex=2,col="#00000055" )
abline(coef(m)[1],coef(m)[2],col="red",lwd=2,lty=2) # Linear regression on the data
abline(coef(m)[1],-0.5,col="grey",lwd=2,lty=2) # Slope in m-v trend according to poisson distribution
points(X1[ERCC],Y1[ERCC],pch=19,col="green",cex=0.5)
```
Our fit (red line) represents, for this dataset, the expected variance of a gene when the only source of variance is technical (because of sampling).
Genes that fall far above this line are  *overdispersed* and should be enriched for genes the fluctuation of which is of biological origin. 



## Cell and Gene Filtering
The goal of this section is to perform a clean-up of the dataset in two dimensions:
First to remove low quality cells that might otherwise be mistaken for distinct meaningful groupings.
Second to remove uninformative genes so as to bring out the true biological differences and remove as much as possible of the technical variation.
To this end we shall use several of the indices introduced in the previous section. 

Although the exact parameters of filtering largely depend on the specific platform used and the specifics of the experiment the criteria used below can be applied with small modifications to any SC experiment. As a general guideline we should make an effort to remove  clear outlier cells/noisy genes but still be conservative enough so as to avoid throwing out cells/genes with differences of truly biological origin.

### Cell filtering
We will remove cells according to two criteria introduced above:

* Number of detected genes: In a plot of the number of the detected genes of the cells vs the corresponding rank we often observe a point of sudden drop (a shoulder). Numbers below that point might indicate damaged cells:
```{r filter_low_NODG}
NODG=colSums(umi_counts>0)
plot (  rank(-NODG)  , NODG ,col=as.numeric(anno[,4]),pch=19 )
abline(5500,0,col="red")
low_NODG=which(NODG<5500)
```


* Fraction of MT reads: As noted previously high fractions of MT reads might indicate damaged cells. We will look, as in the case of number of detected genes, for a point in the plot where the fraction of MT reads of the cells when sorted by their rank appear to rise sharply:
```{r filter_high_MT}
fractionMTreads=colSums(umi_counts[mt,])/colSums(umi_counts)
plot (  rank(fractionMTreads)  , fractionMTreads,col=as.numeric(anno[,4]),pch=19 )
abline(0.11,0,col="red")
high_MT=which(fractionMTreads>0.11)
```

We will now combine the three applied filters to obtain a list of all cells that will be removed and obtain filtered versions of our data:
```{r filter_cells}
filtered_cells=unique(c(low_NODG,high_MT))
clean_umi_counts=umi_counts[,-filtered_cells]
clean_norm_umi_counts=norm_umi_counts[,-filtered_cells] 
clean_anno=anno[-filtered_cells,]
```

Let's check the result of our cell filtering in a plot that combines information about library size, number of detected genes and proportion of MT reads:
```{r filter_cells_plot}
point.size=rep(1,ncol(umi_counts))
Log_library_size= log2(colSums(umi_counts))
point.size=0.25 + ( Log_library_size -min( Log_library_size  ) )/  diff(range( Log_library_size ) )   #Point size proportional to library size 
col=rep("black",ncol(umi_counts))
col[filtered_cells]="grey"
plot(log2(colSums(umi_counts>0)),colSums(umi_counts[mt,])/colSums(umi_counts), pch=19,cex=point.size,col=col,xlab="Log2(Number of Detected Genes)", ylab="Fraction of MT reads")
```


### Gene filtering
The goal here is to throw out genes that offer no information as to the biological variance of the cells. We will now work on the cell-filtered version of our data.
A first simple gene filter is to remove all genes that are not detected in ANY of the remaining cells:
```{r absent_genes}
absent_genes=which(rowSums(clean_umi_counts)==0)
clean_umi_counts=clean_umi_counts[-absent_genes,]
clean_norm_umi_counts=clean_norm_umi_counts[-absent_genes,] 
endog=setdiff(endog,rownames(umi_counts)[absent_genes])
```

A second more elaborate filter will aim to remove genes that do not present cell-to-cell fluctuations above what is expected due to technical variation. 
One possible approach would be to use the mean-variance trend fit constructed above and keep only genes falling above the fitted line:
```{r mean_cv_plot2}
mean_GE=rowMeans(clean_norm_umi_counts+1/ncol(clean_norm_umi_counts))
gene_cv=apply(clean_norm_umi_counts,1, function(x) sd(x)/mean(x+1/length(x)) )
X1=log2(mean_GE)
Y1=log2(gene_cv+1/ncol(clean_norm_umi_counts)  )
m=lm(Y1[endog] ~ X1[endog])
Yhat=predict(m)
col=rep("black",length(Y1))
col[which(Yhat>Y1[endog])]="grey"
plot(X1[endog],Y1[endog],xlab="log2(mean gene expression)",ylab="log2(coefficent of variation)" ,main="mean-variance trend",pch=19 ,col=col)
abline(coef(m)[1],coef(m)[2],col="red",lwd=2,lty=2) # Linear regression on the data
```

A somewhat better approach that relies on fewer assumptions about the mean-variance relationship is to split the genes in bins according to their gene expression and then select the top x% overdispersed genes from every bin. This is achieved using the select_variable_genes function which can be found in the helper functions.R script:
```{r select_overdispersed}
genes_keep <- select_variable_genes(clean_norm_umi_counts[endog,],0.5) ##Specify the normalized count matrix and fraction of overdispersed genes to retain
```

Let's look where our selected genes fall on our mean-variance trend plot:
```{r mean_cv_plot3}
col=rep("grey",length(endog) )
col[genes_keep]="black"
plot(X1[endog],Y1[endog],xlab="log2(mean gene expression)",ylab="log2(coefficent of variation)" ,main="mean-variance trend" ,pch=19,col=col)
abline(coef(m)[1],coef(m)[2],col="red",lwd=2,lty=2) # Linear regression on the data
```
As you can see the effect on this particular dataset is very subtle compared to the previous approach but in different datasets the effect can be more pronounced.

Note that this gene-filtering approach did not explicitly remove any of the over-abundant mitochondrial/ribosomal proteing genes we mentioned earlier.
In practice we suggest removing these genes during the first steps of the analysis (as they can be a source of large spurious variance between cells).


# Single Cell Analysis Tutorial Part 2


## Data Visualization (PCA and tSNE)
In this section we will illustrate different ways to visualize our data using two commonly used projection techniques, namely Principal Component Analysis (PCA) and t-Distributed Stochastic Neighbor Embedding (tSNE). We will also use these techniques to illustrate what is the effect of selecting only a top fraction of overdispersed genes for data visualization (and consequently cell clustering). 

### PCA
Principal Component Analysis is a linear transformation procedure that identifies the directions of maximum variance in high-dimensional data and projects it in a lower dimension subspace. Every direction is orthogonal to the previously identified ones and therefore the final result is a projection on a new coordinate system that still retains the maximum possible variance. 
A perhaps more intuitive explanation is that PCA seeks summary features (i.e components), that are originally not explicitly there, that capture well the overall dispersion (variance) of our data. Each subsequent summary feature (component) captures the maximum possible dispersion left behind from the previous components. The only condition is that every new summary feature must be uncorrelated (i.e orthogonal) to all the previous ones. Therefore each added summary feature will account for progressively lower fractions of the overall dataset dispersion. A dataset where only a handful of such summary features capture a large part of its overall dispersion can thus be nicely summarized with a number of new features that is only a small fraction of the original ones.


* PCA without selecting for overdispersed genes. 

We will try PCA without any filter for dispersion feeding a simple log transformation of the count matrix:
First let's perform PCA and look at the proportion of explained variance by the first 50 components:

```{r PCA_no_selection}
LogTransf_counts=log2(clean_norm_umi_counts[endog,]+1)
PCA_noSel=prcomp(x=t(LogTransf_counts),scale=T) #Note that for prcomp we need to pass a trnasposed version of the matrix where cells are the rows and genes the columns
plot(summary(PCA_noSel)$importance[3,1:50],type="l",xlab="#PC (LogTrans. Data)",ylab="Cum. Proportion of Explained Variance")
Log_NODG=log2(colSums(clean_norm_umi_counts>0)+1) # Calculate also the number of detected genes (to use later in plotting)
datt=data.frame(logNODG=Log_NODG,Batch=clean_anno[,4],PCA_noSel=PCA_noSel$x[,1:2])  # to ease plotting combine results in a dataframe 
```

Now let's project...
```{r PCA_no_selection_plot1}
chart_logNODG=ggplot(datt,aes(x=PCA_noSel.PC1,y=PCA_noSel.PC2,color=logNODG))
chart_logNODG=chart_logNODG+scale_color_gradient(low="#FF5544",high="#4455FF")
chart_logNODG=chart_logNODG+geom_point(size=4,alpha=0.8)
chart_batch=ggplot(datt,aes(x=PCA_noSel.PC1,y=PCA_noSel.PC2,color=Batch))
chart_batch=chart_batch+geom_point(size=4,alpha=0.8)
grid.arrange(chart_logNODG, chart_batch, ncol=1)
```



* PCA after selecting for overdispersed genes. 

We will now see what is the effect on selecting overdispersed genes prior to PCA. Let's select the top 25% overdispersed genes and perform PCA on this subset of our dataset:
```{r PCA_selection}
genes_keep <- endog[select_variable_genes(clean_norm_umi_counts[endog,],0.25)] #Select the top 25% of overdispersed genes
LogTransf_counts=log2(clean_norm_umi_counts[genes_keep ,]+1)
PCA_Sel=prcomp(x=t(LogTransf_counts),scale=T) #Note that for prcomp we need to pass a trnasposed version of the matrix where cells are the rows and genes the columns
plot(summary(PCA_Sel)$importance[3,1:50],type="l",xlab="#PC (LogTrans. Data)",ylab="Cum. Proportion of Explained Variance")
datt=data.frame(logNODG=Log_NODG,Batch=clean_anno[,4],PCA_Sel=PCA_Sel$x[,1:2])  # to ease plotting combine results in a dataframe 
```


Let's project again...
First using the PCA on the Log transformed data:
```{r PCA_selection_plot1}
chart_logNODG=ggplot(datt,aes(x=PCA_Sel.PC1,y=PCA_Sel.PC2,color=logNODG))
chart_logNODG=chart_logNODG+scale_color_gradient(low="#FF5544",high="#4455FF")
chart_logNODG=chart_logNODG+geom_point(size=4,alpha=0.8)
chart_batch=ggplot(datt,aes(x=PCA_Sel.PC1,y=PCA_Sel.PC2,color=Batch))
chart_batch=chart_batch+geom_point(size=4,alpha=0.8)
grid.arrange(chart_logNODG, chart_batch, ncol=1)
```




### tSNE
tSNE is a **non-linear**, **stochastic**  projection technique that attempts to find a mapping of the data on a low subspace while preserving local distances between cells.
The non-linear character of tSNE means that often is will produce projections that better resolve differences between cell groups. The better separation of tSNE comes at the cost of interpretability:
While in a tSNE projection similar cells are guaranteed to end up nearby, longer distances in the projection **cannot** are not guaranteed to reflect true relationships. This means that it is risky to draw conclusions of "similarity" or "dissimilarity" from the positional relationships of different cell groupings that appear in a tSNE projection.
In addition, the stochastic nature of tSNE means that every time the algorithm is applied a different projection will be produced **unlesss a random seed is set**. 

We will first apply QC on the data before filtering for overdispersed genes using the PCA_noSel object from the previous section:
```{r tSNE_no_selection_plot}
tSNE=Rtsne(X=PCA_noSel$x[,1:50],dim=2,perplexity=min(50,round(sqrt(nrow(PCA_noSel$x)))),theta=0.25,pca=F,is_distance = F)  
datt=data.frame(logNODG=Log_NODG,Batch=clean_anno[,4],tSNE=tSNE$Y)  # to ease plotting combine results in a dataframe 
chart_tSNE1=ggplot(datt,aes(x=tSNE.1,y=tSNE.2,color=logNODG))
chart_tSNE1=chart_tSNE1+scale_color_gradient(low="#FF5544",high="#4455FF")
chart_tSNE1=chart_tSNE1+geom_point(size=4,alpha=0.8)
chart_tSNE2=ggplot(datt,aes(x=tSNE.1,y=tSNE.2,color=Batch))
chart_tSNE2=chart_tSNE2+geom_point(size=4,alpha=0.8)
grid.arrange(chart_tSNE1, chart_tSNE2, ncol=1)
```

Now we will repeat the projection using the PCA_Sel object from the previous section:

```{r tSNE_selection_plot}
tSNE=Rtsne(X=PCA_Sel$x[,1:50],dim=2,perplexity=min(50,round(sqrt(nrow(PCA_Sel$x)))),theta=0.25,pca=F,is_distance = F)  
datt=data.frame(logNODG=Log_NODG,Batch=clean_anno[,4],tSNE=tSNE$Y)  # to ease plotting combine results in a dataframe 
chart_tSNE1=ggplot(datt,aes(x=tSNE.1,y=tSNE.2,color=logNODG))
chart_tSNE1=chart_tSNE1+scale_color_gradient(low="#FF5544",high="#4455FF")
chart_tSNE1=chart_tSNE1+geom_point(size=4,alpha=0.8)
chart_tSNE2=ggplot(datt,aes(x=tSNE.1,y=tSNE.2,color=Batch))
chart_tSNE2=chart_tSNE2+geom_point(size=4,alpha=0.8)
grid.arrange(chart_tSNE1, chart_tSNE2, ncol=1)
```





## Identification of confounding factors and correction for unwanted sources of variance




## Identification of meaningful biological cell groupings (clustering) 

```{r griph, message=FALSE}
griph_res <- griph_cluster(as.matrix(clean_norm_umi_counts[endog,]), ClassAssignment=clean_anno[,4],plot=FALSE,rho=0.4)
plotLVis(griph_res, fill.type = "true", line.type = "predicted", mark.type=clean_anno[,1])
```

We will now re-run griph specifying the originating chip as a batch. Connections between cells of the same batch will be penalized, changing the topology of the graph:

```{r griph_batch, message=FALSE}
griph_res_batch <- griph_cluster(as.matrix(clean_norm_umi_counts[endog,]),BatchAssignment=clean_anno[,4], ClassAssignment=clean_anno[,4],batch.penalty=1 ,plot=FALSE,rho=0.4)
plotLVis(griph_res_batch, fill.type = "true", line.type = "predicted", mark.type=clean_anno[,1] )
```

## Differential gene expression 





```{r setup_documentation, echo=FALSE, message=FALSE, results='hide'}
#### Copy the created html to master root as index.html
#### and the md as README.md
  file.copy("Tutorial.html","index.html",overwrite=TRUE)
  file.copy("Tutorial.md","README.md",overwrite=TRUE)
```

